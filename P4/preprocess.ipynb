{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cores:  4\n"
     ]
    }
   ],
   "source": [
    "import Bio as bp\n",
    "from Bio.Seq import Seq\n",
    "from Bio.Alphabet import generic_dna\n",
    "import itertools\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "import re\n",
    "import copy\n",
    "\n",
    "import pandas as pd\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "print(\"cores: \",num_cores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 4-mers: 256\n",
      "Complement 4-mers: 136\n",
      "dict_keys(['AAAA', 'AAAC', 'AAAT', 'AAAG', 'AACA', 'AACC', 'AACT', 'AACG', 'AATA', 'AATC', 'AATT', 'AATG', 'AAGA', 'AAGC', 'AAGT', 'AAGG', 'ACAA', 'ACAC', 'ACAT', 'ACAG', 'ACCA', 'ACCC', 'ACCT', 'ACCG', 'ACTA', 'ACTC', 'ACTG', 'ACGA', 'ACGC', 'ACGT', 'ACGG', 'ATAA', 'ATAC', 'ATAT', 'ATAG', 'ATCA', 'ATCC', 'ATCT', 'ATCG', 'ATTA', 'ATTC', 'ATTG', 'ATGA', 'ATGC', 'ATGG', 'AGAA', 'AGAC', 'AGAG', 'AGCA', 'AGCC', 'AGCT', 'AGCG', 'AGTA', 'AGTC', 'AGTG', 'AGGA', 'AGGC', 'AGGG', 'CAAA', 'CAAC', 'CAAG', 'CACA', 'CACC', 'CACG', 'CATA', 'CATC', 'CATG', 'CAGA', 'CAGC', 'CAGG', 'CCAA', 'CCAC', 'CCAG', 'CCCA', 'CCCC', 'CCCG', 'CCTA', 'CCTC', 'CCGA', 'CCGC', 'CCGG', 'CTAA', 'CTAC', 'CTAG', 'CTCA', 'CTCC', 'CTCG', 'CTTA', 'CTTC', 'CTGA', 'CTGC', 'CGAA', 'CGAC', 'CGCA', 'CGCC', 'CGCG', 'CGTA', 'CGTC', 'CGGA', 'CGGC', 'TAAA', 'TAAC', 'TACA', 'TACC', 'TATA', 'TATC', 'TAGA', 'TAGC', 'TCAA', 'TCAC', 'TCCA', 'TCCC', 'TCTC', 'TCGA', 'TCGC', 'TTAA', 'TTAC', 'TTCA', 'TTCC', 'TTTC', 'TTGC', 'TGAC', 'TGCA', 'TGCC', 'TGTC', 'TGGC', 'GAAC', 'GACC', 'GATC', 'GAGC', 'GCAC', 'GCCC', 'GCGC', 'GTAC', 'GTCC', 'GGCC'])\n"
     ]
    }
   ],
   "source": [
    "fours = {}\n",
    "letters = ['A', 'C', 'T', 'G']\n",
    "print(\"All 4-mers:\",len(list(itertools.product(letters, repeat=4))))\n",
    "products = list(itertools.product(letters, repeat=4))\n",
    "\n",
    "for i, el in enumerate(products):\n",
    "    joined_el = \"\".join(el)\n",
    "    my_dna = Seq(joined_el, generic_dna)\n",
    "    reversed_compliment = str(my_dna.reverse_complement())\n",
    "    if joined_el not in fours.keys() and reversed_compliment not in fours.keys():\n",
    "        fours[joined_el] = 0\n",
    "        \n",
    "print(\"Complement 4-mers:\",len(fours.keys()))\n",
    "print(fours.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count(fragment, patterns_dictionary, step = 1, range_length = 4):\n",
    "    \"\"\"\n",
    "    range length == 4\n",
    "    \"\"\"\n",
    "    n = len(fragment)\n",
    "    for i in range(0, n, step):\n",
    "        if i + range_length >= n:\n",
    "            break\n",
    "        curr = fragment[i:(i+range_length)]\n",
    "\n",
    "        if curr in patterns_dictionary:\n",
    "            patterns_dictionary[curr] += 1\n",
    "        else:\n",
    "            my_dna = Seq(joined_el, generic_dna)\n",
    "            reversed_compliment = str(my_dna.reverse_complement())\n",
    "            if reversed_compliment in patterns_dictionary:\n",
    "                patterns_dictionary[reversed_compliment] += 1\n",
    "            else:\n",
    "                print(\"Non-matched sequence\")\n",
    "    return patterns_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=fours.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "positives_file = 'vista1500'\n",
    "negatives_file = 'randoms1500'\n",
    "\n",
    "positives_list = []\n",
    "negatives_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(positives_file) as fp:\n",
    "    line = fp.readline()\n",
    "    line = fp.readline()\n",
    "    while line:\n",
    "        positives_list.append(line\n",
    "                              .upper()\n",
    "                              .strip())\n",
    "        line = fp.readline()\n",
    "        line = fp.readline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3398"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(positives_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(negatives_file) as fp:\n",
    "    line = fp.readline()\n",
    "    line = fp.readline()\n",
    "    while line:\n",
    "        #print(\"linia:\", line.upper())\n",
    "        negatives_list.append(line\n",
    "                              .upper()\n",
    "                              .strip())\n",
    "        line = fp.readline()\n",
    "        line = fp.readline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1272"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(negatives_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3398\n",
      "1272\n"
     ]
    }
   ],
   "source": [
    "# positives_list = positives_list[:600]\n",
    "# negatives_list = negatives_list[:600]\n",
    "n_1 = len(positives_list)\n",
    "n_2 = len(negatives_list)\n",
    "print(n_1)\n",
    "print(n_2)\n",
    "result_dict = {}\n",
    "\n",
    "labels_positive = (n_1) * [1]\n",
    "labels_negative = (n_2) * [0]\n",
    "labels = [*labels_positive, *labels_negative]\n",
    "\n",
    "for i in fours.keys():\n",
    "    result_dict[i] = [0] * (n_1+n_2)\n",
    "    \n",
    "for i, el in enumerate(itertools.chain(positives_list, negatives_list)):\n",
    "    pass\n",
    "    #data_point = copy.copy(fours)\n",
    "    data_point = count(el, copy.copy(fours))\n",
    "    for j in result_dict.keys():\n",
    "        result_dict[j][i] = data_point[j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(result_dict)\n",
    "df['labels'] = labels\n",
    "mat = df.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1200, 137)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[20 10 16 ...  3  2  5]\n",
      " [31 10 17 ...  1  3  4]\n",
      " [16  3 13 ...  4  2  1]\n",
      " ...\n",
      " [14  5  8 ...  0  0 10]\n",
      " [17  9 15 ...  1  3  5]\n",
      " [25 12 21 ...  3  0  1]]\n",
      "[1 1 1 ... 1 0 0]\n",
      "(4670, 136)\n",
      "(4670,)\n"
     ]
    }
   ],
   "source": [
    "mat_x = mat[:, :136]\n",
    "mat_y = mat[:, 136]\n",
    "print(mat_x)\n",
    "print(mat_y)\n",
    "print(mat_x.shape)\n",
    "print(mat_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1017"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(mat_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4670, 136)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_x = np.divide(mat_x, np.max(mat_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kolumnami\n",
    "np.max(mat_x, axis=0).reshape([1,136]).shape\n",
    "mat_x = np.divide(mat_x, np.max(mat_x, axis=0).reshape([1,136]))\n",
    "#tu powinna byc normalizacja po kolumnach a nie po calej macierzy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wierszami\n",
    "m,n = mat_x.shape\n",
    "np.max(mat_x, axis=1).reshape([m,1]).shape\n",
    "mat_x = np.divide(mat_x, np.max(mat_x, axis=1).reshape([m,1]))\n",
    "#tu powinna byc normalizacja po kolumnach a nie po calej macierzy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4670,)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(mat_x, axis=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wczytanie testowego"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitted chr21: 62280\n",
      "Splitted chr21 without NA: 53355\n"
     ]
    }
   ],
   "source": [
    "with open(\"chr21.fa\") as f:\n",
    "    file_string = f.read()\n",
    "\n",
    "file_string = re.sub(\"\\n\", \"\", file_string)\n",
    "file_string = file_string[7:]\n",
    "\n",
    "chr_split = []\n",
    "for i in range(0, len(file_string), 750):\n",
    "    chr_split.append(file_string[i:(i+1500)].upper())\n",
    "    \n",
    "chr_split_without_NA = []\n",
    "chr_split_without_NA_indexes = []\n",
    "\n",
    "for i,el in enumerate(chr_split):\n",
    "    if re.search(\"N\", el) is None:\n",
    "        chr_split_without_NA.append(el) \n",
    "        chr_split_without_NA_indexes.append(i)\n",
    "\n",
    "print(\"Splitted chr21:\",len(chr_split))\n",
    "print(\"Splitted chr21 without NA:\", len(chr_split_without_NA))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(positives_list = [], negatives_list = [], test_list = []):\n",
    "    \n",
    "    def to_parallel(i, el):\n",
    "        nonlocal result_dict\n",
    "        data_point = count(el, copy.copy(fours))\n",
    "        for j in result_dict.keys():\n",
    "            result_dict[j][i] = data_point[j]\n",
    "    \n",
    "    result_dict = {}\n",
    "    \n",
    "    n_1 = len(positives_list)\n",
    "    n_2 = len(negatives_list)\n",
    "    n_3 = len(test_list)\n",
    "    \n",
    "    labels_positive = (n_1) * [1]\n",
    "    labels_negative = (n_2) * [0]\n",
    "    labels_test = (n_3) * [-1]\n",
    "    labels = [*labels_positive, *labels_negative, *labels_test]\n",
    "    \n",
    "    for i in fours.keys():\n",
    "        result_dict[i] = [0] * (n_1+n_2+n_3)\n",
    "#     Parallel(n_jobs=num_cores)(delayed(to_parallel(i, el) for i, el in enumerate(itertools.chain(positives_list, negatives_list, test_list))))\n",
    "    \n",
    "    for i, el in enumerate(tqdm(itertools.chain(positives_list, negatives_list, test_list))):\n",
    "        data_point = count(el, copy.copy(fours))\n",
    "        for j in result_dict.keys():\n",
    "            result_dict[j][i] = data_point[j]\n",
    "    return result_dict, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "53355it [05:14, 169.73it/s]\n"
     ]
    }
   ],
   "source": [
    "rt = create_dataset(test_list=chr_split_without_NA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(list(np.var(pd.DataFrame(rt[0]).to_numpy(), axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.DataFrame(rt[0]).to_numpy()\n",
    "\n",
    "m,n = test.shape\n",
    "np.max(test, axis=1).reshape([m,1]).shape\n",
    "test = np.divide(test, np.max(test, axis=1).reshape([m,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.02125   , 0.00625   , 0.00875   , ..., 0.0025    , 0.0025    ,\n",
       "        0.0075    ],\n",
       "       [0.02970297, 0.00848656, 0.00990099, ..., 0.00424328, 0.00990099,\n",
       "        0.00565771],\n",
       "       [0.00879765, 0.00293255, 0.00439883, ..., 0.0058651 , 0.01759531,\n",
       "        0.02346041],\n",
       "       ...,\n",
       "       [0.04444444, 0.01045752, 0.01568627, ..., 0.00653595, 0.00653595,\n",
       "        0.00261438],\n",
       "       [0.04513399, 0.00987306, 0.00705219, ..., 0.00564175, 0.01269394,\n",
       "        0.00846262],\n",
       "       [0.00291121, 0.00291121, 0.        , ..., 0.0014556 , 0.00582242,\n",
       "        0.00582242]])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_labels = np.zeros([mat_x.shape[0], 2])\n",
    "for i in range(mat_labels.shape[0]):\n",
    "    mat_labels[i, mat_y[i]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1200, 2)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat_labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 60\n",
    "X = torch.Tensor(mat_x[train_size:, :])\n",
    "y = torch.Tensor(mat_labels[train_size:, :])\n",
    "X_test = torch.Tensor(mat_x[:train_size,:])\n",
    "y_test = torch.Tensor(mat_labels[:train_size, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1140, 136])\n",
      "torch.Size([1140, 2])\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.jeden = nn.Linear(136, 32)\n",
    "        self.trzy = nn.Linear(32, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.jeden(x))\n",
    "        x = F.relu(self.trzy(x))\n",
    "        return F.softmax(x, dim=1)\n",
    "\n",
    "# class Net(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "#         self.jeden = nn.Linear(136, 64)\n",
    "#         self.dwa = nn.Linear(64, 32)\n",
    "#         self.trzy = nn.Linear(32, 2)\n",
    "        \n",
    "#     def forward(self, x):\n",
    "#         x = F.relu(self.jeden(x))\n",
    "#         x = F.relu(self.dwa(x))\n",
    "#         x = F.relu(self.trzy(x))\n",
    "#         return F.softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "loss_function = nn.MSELoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1185, 136])"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([136])"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0. Loss: 0.25710776448249817\n",
      "Epoch: 1. Loss: 0.25793012976646423\n",
      "Epoch: 2. Loss: 0.2592150568962097\n",
      "Epoch: 3. Loss: 0.26220613718032837\n",
      "Epoch: 4. Loss: 0.2653394341468811\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 5\n",
    "EPOCHS = 5\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    for i in range(0, X.shape[0], BATCH_SIZE):\n",
    "        #print(f\"{i}:{i+BATCH_SIZE}\")\n",
    "        batch_X = X[i:i+BATCH_SIZE]\n",
    "        batch_y = y[i:i+BATCH_SIZE]\n",
    "\n",
    "        net.zero_grad()\n",
    "\n",
    "        outputs = net(batch_X)\n",
    "        loss = loss_function(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()    # Does the update\n",
    "\n",
    "    print(f\"Epoch: {epoch}. Loss: {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:00<00:00, 2569.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for i in tqdm(range(len(X_test))):\n",
    "        real_class = torch.argmax(y_test[i])\n",
    "        net_out = net(X_test[i].view(1,136))[0]  # returns a list, \n",
    "        predicted_class = torch.argmax(net_out)\n",
    "\n",
    "        if predicted_class == real_class:\n",
    "            correct += 1\n",
    "        total += 1\n",
    "print(\"Accuracy: \", round(correct/total, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([136, 1])"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[1].view(136,1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 136])"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[2:5].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1185, 136])"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5029, 0.4971]], grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.forward(X[3].view(1,136))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4771, 0.5229],\n",
       "        [0.4635, 0.5365],\n",
       "        [0.4677, 0.5323],\n",
       "        [0.4574, 0.5426],\n",
       "        [0.4434, 0.5566],\n",
       "        [0.4704, 0.5296],\n",
       "        [0.4439, 0.5561],\n",
       "        [0.4658, 0.5342]], grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.forward(X[2:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logisticRegr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ghost/.virtualenvs/p7def/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logisticRegr.fit(mat_x, mat_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75"
      ]
     },
     "execution_count": 446,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logisticRegr.score(X_test, y_test[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = logisticRegr.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53283"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.count_nonzero(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "randFor = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ghost/.virtualenvs/p7def/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "randFor.fit(mat_x, mat_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = randFor.predict_proba(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "104698"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.count_nonzero(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Result Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = len(chr_split) * [np.mean(pred)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, el in enumerate(chr_split_without_NA_indexes):\n",
    "    result[el] = pred[i][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "wig_string = \"fixedStep chrom=chr21 start=0 step=750 span=1500\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in result:\n",
    "    wig_string += str(i) + \" \\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"predict.wig\", \"w\") as f:\n",
    "    f.write(wig_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
