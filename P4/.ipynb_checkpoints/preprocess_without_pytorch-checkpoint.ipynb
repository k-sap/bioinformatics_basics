{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to bioinformatics\n",
    "## Project no. 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cores:  4\n"
     ]
    }
   ],
   "source": [
    "import Bio as bp\n",
    "from Bio.Seq import Seq\n",
    "from Bio.Alphabet import generic_dna\n",
    "import itertools\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "import re\n",
    "import copy\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "print(\"cores: \",num_cores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4-mers dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 4-mers: 256\n",
      "Complement 4-mers: 136\n",
      "dict_keys(['AAAA', 'AAAC', 'AAAT', 'AAAG', 'AACA', 'AACC', 'AACT', 'AACG', 'AATA', 'AATC', 'AATT', 'AATG', 'AAGA', 'AAGC', 'AAGT', 'AAGG', 'ACAA', 'ACAC', 'ACAT', 'ACAG', 'ACCA', 'ACCC', 'ACCT', 'ACCG', 'ACTA', 'ACTC', 'ACTG', 'ACGA', 'ACGC', 'ACGT', 'ACGG', 'ATAA', 'ATAC', 'ATAT', 'ATAG', 'ATCA', 'ATCC', 'ATCT', 'ATCG', 'ATTA', 'ATTC', 'ATTG', 'ATGA', 'ATGC', 'ATGG', 'AGAA', 'AGAC', 'AGAG', 'AGCA', 'AGCC', 'AGCT', 'AGCG', 'AGTA', 'AGTC', 'AGTG', 'AGGA', 'AGGC', 'AGGG', 'CAAA', 'CAAC', 'CAAG', 'CACA', 'CACC', 'CACG', 'CATA', 'CATC', 'CATG', 'CAGA', 'CAGC', 'CAGG', 'CCAA', 'CCAC', 'CCAG', 'CCCA', 'CCCC', 'CCCG', 'CCTA', 'CCTC', 'CCGA', 'CCGC', 'CCGG', 'CTAA', 'CTAC', 'CTAG', 'CTCA', 'CTCC', 'CTCG', 'CTTA', 'CTTC', 'CTGA', 'CTGC', 'CGAA', 'CGAC', 'CGCA', 'CGCC', 'CGCG', 'CGTA', 'CGTC', 'CGGA', 'CGGC', 'TAAA', 'TAAC', 'TACA', 'TACC', 'TATA', 'TATC', 'TAGA', 'TAGC', 'TCAA', 'TCAC', 'TCCA', 'TCCC', 'TCTC', 'TCGA', 'TCGC', 'TTAA', 'TTAC', 'TTCA', 'TTCC', 'TTTC', 'TTGC', 'TGAC', 'TGCA', 'TGCC', 'TGTC', 'TGGC', 'GAAC', 'GACC', 'GATC', 'GAGC', 'GCAC', 'GCCC', 'GCGC', 'GTAC', 'GTCC', 'GGCC'])\n"
     ]
    }
   ],
   "source": [
    "fours = {}\n",
    "letters = ['A', 'C', 'T', 'G']\n",
    "print(\"All 4-mers:\",len(list(itertools.product(letters, repeat=4))))\n",
    "products = list(itertools.product(letters, repeat=4))\n",
    "\n",
    "for i, el in enumerate(products):\n",
    "    joined_el = \"\".join(el)\n",
    "    my_dna = Seq(joined_el, generic_dna)\n",
    "    reversed_compliment = str(my_dna.reverse_complement())\n",
    "    if joined_el not in fours.keys() and reversed_compliment not in fours.keys():\n",
    "        fours[joined_el] = 0\n",
    "        \n",
    "print(\"Complement 4-mers:\",len(fours.keys()))\n",
    "print(fours.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count(fragment, patterns_dictionary, step = 1, range_length = 4):\n",
    "    \"\"\"\n",
    "    range length == 4\n",
    "    \"\"\"\n",
    "    n = len(fragment)\n",
    "    for i in range(0, n, step):\n",
    "        if i + range_length >= n:\n",
    "            break\n",
    "        curr = fragment[i:(i+range_length)]\n",
    "\n",
    "        if curr in patterns_dictionary:\n",
    "            patterns_dictionary[curr] += 1\n",
    "        else:\n",
    "            my_dna = Seq(joined_el, generic_dna)\n",
    "            reversed_compliment = str(my_dna.reverse_complement())\n",
    "            if reversed_compliment in patterns_dictionary:\n",
    "                patterns_dictionary[reversed_compliment] += 1\n",
    "            else:\n",
    "                print(\"Non-matched sequence\")\n",
    "    return patterns_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(positives_list = [], negatives_list = [], test_list = []):\n",
    "    \n",
    "    def to_parallel(i, el):\n",
    "        nonlocal result_dict\n",
    "        data_point = count(el, copy.copy(fours))\n",
    "        for j in result_dict.keys():\n",
    "            result_dict[j][i] = data_point[j]\n",
    "    \n",
    "    result_dict = {}\n",
    "    \n",
    "    n_1 = len(positives_list)\n",
    "    n_2 = len(negatives_list)\n",
    "    n_3 = len(test_list)\n",
    "    \n",
    "    labels_positive = (n_1) * [1]\n",
    "    labels_negative = (n_2) * [0]\n",
    "    labels_test = (n_3) * [-1]\n",
    "    labels = [*labels_positive, *labels_negative, *labels_test]\n",
    "    \n",
    "    for i in fours.keys():\n",
    "        result_dict[i] = [0] * (n_1+n_2+n_3)\n",
    "#     Parallel(n_jobs=num_cores)(delayed(to_parallel(i, el) for i, el in enumerate(itertools.chain(positives_list, negatives_list, test_list))))\n",
    "    \n",
    "    for i, el in enumerate(tqdm(itertools.chain(positives_list, negatives_list, test_list))):\n",
    "        data_point = count(el, copy.copy(fours))\n",
    "        for j in result_dict.keys():\n",
    "            result_dict[j][i] = data_point[j]\n",
    "    return result_dict, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "positives_file = 'vista1500'\n",
    "negatives_file = 'randoms1500'\n",
    "\n",
    "positives_list = []\n",
    "negatives_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(positives_file) as fp:\n",
    "    line = fp.readline()\n",
    "    line = fp.readline()\n",
    "    while line:\n",
    "        positives_list.append(line\n",
    "                              .upper()\n",
    "                              .strip())\n",
    "        line = fp.readline()\n",
    "        line = fp.readline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(negatives_file) as fp:\n",
    "    line = fp.readline()\n",
    "    line = fp.readline()\n",
    "    while line:\n",
    "        negatives_list.append(line\n",
    "                              .upper()\n",
    "                              .strip())\n",
    "        line = fp.readline()\n",
    "        line = fp.readline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1699 636\n"
     ]
    }
   ],
   "source": [
    "print(len(positives_list), len(negatives_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2335it [00:10, 219.57it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset_dict, labels = create_dataset(positives_list=positives_list, negatives_list=negatives_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(dataset_dict)\n",
    "df['labels'] = labels\n",
    "mat = df.to_numpy()\n",
    "np.random.shuffle(mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[17  5 13 ...  4  2  0]\n",
      " [28 10 16 ...  5  4  2]\n",
      " [20 11 17 ...  0  2  5]\n",
      " ...\n",
      " [10  6 11 ...  5  1  4]\n",
      " [11  2 12 ...  0  3  8]\n",
      " [22  6 16 ...  1  4  3]]\n",
      "[0 1 1 ... 1 0 1]\n",
      "(2335, 136)\n",
      "(2335,)\n"
     ]
    }
   ],
   "source": [
    "mat_x = mat[:, :136]\n",
    "mat_y = mat[:, 136]\n",
    "print(mat_x)\n",
    "print(mat_y)\n",
    "print(mat_x.shape)\n",
    "print(mat_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalizacja wierszami\n",
    "m,n = mat_x.shape\n",
    "np.max(mat_x, axis=1).reshape([m,1]).shape\n",
    "mat_x = np.divide(mat_x, np.max(mat_x, axis=1).reshape([m,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2335,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(mat_x, axis=1).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train, Validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1868, 136) (467, 136)\n"
     ]
    }
   ],
   "source": [
    "partition_fraction = 0.2\n",
    "partition_index = int(partition_fraction * mat_x.shape[0])\n",
    "\n",
    "mat_x_train = mat_x[partition_index:, :]\n",
    "mat_y_train = mat_y[partition_index:]\n",
    "\n",
    "mat_x_valid = mat_x[:partition_index, :]\n",
    "mat_y_valid = mat_y[:partition_index]\n",
    "\n",
    "print(mat_x_train.shape, mat_x_valid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitted chr21: 62280\n",
      "Splitted chr21 without NA: 53355\n"
     ]
    }
   ],
   "source": [
    "with open(\"chr21.fa\") as f:\n",
    "    file_string = f.read()\n",
    "\n",
    "file_string = re.sub(\"\\n\", \"\", file_string)\n",
    "file_string = file_string[7:]\n",
    "\n",
    "chr_split = []\n",
    "for i in range(0, len(file_string), 750):\n",
    "    chr_split.append(file_string[i:(i+1500)].upper())\n",
    "    \n",
    "chr_split_without_NA = []\n",
    "chr_split_without_NA_indexes = []\n",
    "\n",
    "for i,el in enumerate(chr_split):\n",
    "    if re.search(\"N\", el) is None:\n",
    "        chr_split_without_NA.append(el) \n",
    "        chr_split_without_NA_indexes.append(i)\n",
    "\n",
    "print(\"Splitted chr21:\",len(chr_split))\n",
    "print(\"Splitted chr21 without NA:\", len(chr_split_without_NA))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #rt = create_dataset(test_list=chr_split_without_NA)\n",
    "# test = pd.DataFrame(rt[0]).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.load(\"test.npy\")\n",
    "\n",
    "m,n = test.shape\n",
    "np.max(test, axis=1).reshape([m,1]).shape\n",
    "test = np.divide(test, np.max(test, axis=1).reshape([m,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53355, 136)\n"
     ]
    }
   ],
   "source": [
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest = RandomForestClassifier(n_estimators = 750, max_depth = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=20, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=750,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest.fit(mat_x_train, mat_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7794432548179872"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest.score(mat_x_valid, mat_y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8392275583688821"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_probs = [i[1] for i in random_forest.predict_proba(mat_x_valid)]\n",
    "metrics.roc_auc_score(list(mat_y_valid), pred_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.81948529 0.87095588 0.81746324 0.79889706 0.84071691 0.92426471\n",
      " 0.83697479 0.80690943 0.81886088 0.81083873]\n",
      "0.8345366920190166 0.035749733211969816\n"
     ]
    }
   ],
   "source": [
    "cv_aucs = cross_val_score(random_forest, mat_x, mat_y, cv=10, scoring='roc_auc')\n",
    "print(cv_aucs)\n",
    "print(np.mean(cv_aucs), np.sqrt(np.var(cv_aucs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = random_forest.predict_proba(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Result Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest.fit(mat_x, mat_y)\n",
    "pred = random_forest.predict_proba(test)\n",
    "result = len(chr_split) * [np.mean(pred)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, el in enumerate(chr_split_without_NA_indexes):\n",
    "    result[el] = pred[i][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.050666666666666665"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "wig_string = \"fixedStep chrom=chr21 start=0 step=750 span=1500\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in result:\n",
    "    wig_string += str(i) + \" \\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"predict.wig\", \"w\") as f:\n",
    "#     f.write(wig_string)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
